\begin{abstract}
Hierarchical reinforcement learning (HRL) aims to mimic a human being's natural tendency
to break a task into multiple, manageable sub-problems. HRL methods find the solution to
a reinforcement learning problem by learning optimal solutions to such sub-problems.
As a result of this approach, HRL has advantages in terms of reusability, temporal abstraction, and state abstraction.
In this work we discuss the various approaches to HRL with particular emphasis on recent advances
, which leverage neural networks to approximate value functions.
\end{abstract}


