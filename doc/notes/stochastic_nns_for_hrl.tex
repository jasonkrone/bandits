\section{Stochastic Neural Networks for Hierarchal Reinforcement Learning Michael Chess}

This paper applies a similar style of analysis to the hybrid reward paper but uses a stochastic neural network as the primary learning agent.
The really interesting feature of this approach is that stochastic neural networks naturally 'jump' out of local minima.
This means that in the context of an extremely high dimensional function such as a Q function a minimal representation (in the parameter space) neural network can potentially avoid getting stuck in local minima. 
